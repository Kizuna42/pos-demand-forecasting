"""
ç”Ÿé®®é£Ÿå“éœ€è¦äºˆæ¸¬ãƒ»åˆ†æã‚·ã‚¹ãƒ†ãƒ  ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯å…¨ä½“ã®åˆ†æãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œã—ã€
ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‹ã‚‰æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã¾ã§çµ±åˆçš„ã«å‡¦ç†ã—ã¾ã™ã€‚
"""

import argparse
from pathlib import Path
import sys
from typing import Any, Dict, List

import pandas as pd

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(str(Path(__file__).parent.parent))

from src.demand_forecasting.core.data_processor import DataProcessor
from src.demand_forecasting.core.demand_analyzer import DemandCurveAnalyzer
from src.demand_forecasting.core.feature_engineer import FeatureEngineer
from src.demand_forecasting.core.model_builder import ModelBuilder
from src.demand_forecasting.reports.report_generator import ReportGenerator
from src.demand_forecasting.utils.config import Config
from src.demand_forecasting.utils.logger import Logger
from src.demand_forecasting.utils.quality_evaluator import QualityEvaluator
from src.demand_forecasting.visualization.want_plotter import WantPlotter


class DemandForecastingPipeline:
    """éœ€è¦äºˆæ¸¬åˆ†æãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"""

    def __init__(self, config_path: str = None):
        """
        åˆæœŸåŒ–

        Args:
            config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        self.config = Config(config_path)
        self.logger = Logger(self.config.get_logging_config()).get_logger("main")

        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–
        self.data_processor = DataProcessor(self.config)
        self.feature_engineer = FeatureEngineer(self.config)
        self.model_builder = ModelBuilder(self.config)
        self.demand_analyzer = DemandCurveAnalyzer(self.config)
        self.quality_evaluator = QualityEvaluator(self.config)
        self.plotter = WantPlotter(self.config)
        self.report_generator = ReportGenerator(self.config)

    def run_full_analysis(
        self, target_products: List[str] = None, max_products: int = 10
    ) -> Dict[str, Any]:
        """
        å…¨ä½“åˆ†æã‚’å®Ÿè¡Œ

        Args:
            target_products: å¯¾è±¡å•†å“ãƒªã‚¹ãƒˆ
            max_products: æœ€å¤§å‡¦ç†å•†å“æ•°

        Returns:
            åˆ†æçµæœè¾æ›¸
        """
        self.logger.info("éœ€è¦äºˆæ¸¬åˆ†æãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é–‹å§‹")

        try:
            # 1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†
            self.logger.info("ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†")
            raw_data = self.data_processor.load_raw_data()
            clean_data = self.data_processor.clean_data(raw_data)

            # 2. ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
            self.logger.info("ã‚¹ãƒ†ãƒƒãƒ—2: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°")
            baseline_features = self.feature_engineer.create_baseline_features(clean_data)
            time_features = self.feature_engineer.add_time_features(baseline_features)
            final_features = self.feature_engineer.integrate_weather_features(time_features)

            # 3. åˆ†æå¯¾è±¡å•†å“ã®æ±ºå®š
            if target_products is None:
                # Phase 2: å±¤åŒ–ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§ä»£è¡¨å•†å“ã‚’é¸æŠ
                target_products = self.data_processor.stratified_product_sampling(
                    final_features, max_products=max_products
                )

            self.logger.info(f"åˆ†æå¯¾è±¡å•†å“: {len(target_products)}å•†å“")

            # 4. å•†å“åˆ¥åˆ†æå®Ÿè¡Œ
            analysis_results = []

            for i, product in enumerate(target_products, 1):
                self.logger.info(f"å•†å“åˆ†æ {i}/{len(target_products)}: {product}")

                try:
                    # å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
                    product_data = final_features[final_features["å•†å“åç§°"] == product].copy()

                    if len(product_data) < 100:
                        self.logger.warning(
                            f"ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã«ã‚ˆã‚Š{product}ã‚’ã‚¹ã‚­ãƒƒãƒ— (ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(product_data)})"
                        )
                        continue

                    # æ™‚ç³»åˆ—é€£ç¶šæ€§ãƒ»å­£ç¯€æ€§ãƒã‚§ãƒƒã‚¯
                    if not self._validate_time_series_quality(product_data, product):
                        self.logger.warning(f"æ™‚ç³»åˆ—å“è³ªä¸è‰¯ã«ã‚ˆã‚Š{product}ã‚’ã‚¹ã‚­ãƒƒãƒ—")
                        continue

                    result = self._analyze_single_product(product, product_data, final_features)
                    if result:
                        analysis_results.append(result)

                except Exception as e:
                    self.logger.error(f"å•†å“{product}ã®åˆ†æã«å¤±æ•—: {e}")
                    continue

            # 5. å“è³ªè©•ä¾¡
            self.logger.info("ã‚¹ãƒ†ãƒƒãƒ—3: å“è³ªè©•ä¾¡")
            quality_report = self.quality_evaluator.create_quality_report(analysis_results)

            # 6. å¯è¦–åŒ–ç”Ÿæˆ
            self.logger.info("ã‚¹ãƒ†ãƒƒãƒ—4: å¯è¦–åŒ–ç”Ÿæˆ")
            visualization_files = self._generate_visualizations(analysis_results, quality_report)

            # 7. ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            self.logger.info("ã‚¹ãƒ†ãƒƒãƒ—5: ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ")
            report_files = self._generate_reports(analysis_results, quality_report)

            # çµæœçµ±åˆ
            final_results = {
                "analysis_results": analysis_results,
                "quality_report": quality_report,
                "visualization_files": visualization_files,
                "report_files": report_files,
                "summary": {
                    "total_products_analyzed": len(analysis_results),
                    "success_rate": quality_report.get("summary", {}).get("success_rate", 0.0),
                    "average_r2": quality_report.get("summary", {}).get("average_r2", 0.0),
                },
            }

            self.logger.info("éœ€è¦äºˆæ¸¬åˆ†æãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº†")
            self._log_summary(final_results)

            return final_results

        except Exception as e:
            self.logger.error(f"ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def _analyze_single_product(
        self, product: str, product_data: pd.DataFrame, full_data: pd.DataFrame
    ) -> Dict[str, Any]:
        """å˜ä¸€å•†å“ã®åˆ†æ"""
        try:
            # ç‰¹å¾´é‡é¸æŠ
            target_column = "æ•°é‡"
            if target_column not in product_data.columns:
                self.logger.warning(f"{product}: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ—'{target_column}'ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return None

            # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’åˆ†é›¢
            feature_columns = product_data.select_dtypes(include=["number"]).columns.tolist()
            if target_column in feature_columns:
                feature_columns.remove(target_column)

            if len(feature_columns) < 3:
                self.logger.warning(f"{product}: ç‰¹å¾´é‡ä¸è¶³")
                return None

            X = product_data[feature_columns]
            y = product_data[target_column]

            # æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
            model_results = self.model_builder.train_with_cv(X, y)

            # å“è³ªãƒ¬ãƒ™ãƒ«è©•ä¾¡
            quality_level = self.quality_evaluator.evaluate_quality_level(
                model_results["test_metrics"]["r2_score"]
            )

            # å®Ÿç”¨åŒ–æº–å‚™çŠ¶æ³è©•ä¾¡
            implementation_readiness = self.quality_evaluator.assess_implementation_readiness(
                model_results["test_metrics"]
            )

            # éœ€è¦æ›²ç·šåˆ†æ
            demand_results = None
            try:
                demand_results = self.demand_analyzer.analyze_demand_curve(product_data, product)
            except Exception as e:
                self.logger.warning(f"{product}: éœ€è¦æ›²ç·šåˆ†æå¤±æ•—: {e}")

            # å•†å“ã‚«ãƒ†ã‚´ãƒªå–å¾—
            category = (
                product_data["å•†å“ã‚«ãƒ†ã‚´ãƒª"].iloc[0]
                if "å•†å“ã‚«ãƒ†ã‚´ãƒª" in product_data.columns
                else "ãã®ä»–"
            )

            # çµæœçµ±åˆ
            result = {
                "product_name": product,
                "category": category,
                "quality_level": quality_level,
                "implementation_readiness": implementation_readiness,
                "test_metrics": model_results["test_metrics"],
                "cv_scores": model_results["cv_scores"],
                "overfitting_score": model_results["overfitting_score"],
                "feature_importance": model_results["feature_importance"],
                "model": model_results["model"],
                "feature_names": model_results["feature_names"],
            }

            if demand_results:
                result["demand_results"] = demand_results

            return result

        except Exception as e:
            self.logger.error(f"å•†å“{product}ã®åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def _generate_visualizations(
        self, analysis_results: List[Dict[str, Any]], quality_report: Dict[str, Any]
    ) -> List[str]:
        """å¯è¦–åŒ–ã‚’ç”Ÿæˆ"""
        visualization_files = []

        try:
            # å“è³ªãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
            quality_dashboard_path = self.plotter.create_quality_dashboard(
                quality_report.get("summary", {})
            )
            visualization_files.append(quality_dashboard_path)

            # å€‹åˆ¥å•†å“ã®ãƒ—ãƒ­ãƒƒãƒˆï¼ˆä¸Šä½5å•†å“ã®ã¿ï¼‰
            sorted_results = sorted(
                analysis_results,
                key=lambda x: x.get("test_metrics", {}).get("r2_score", 0),
                reverse=True,
            )[:5]

            for result in sorted_results:
                # éœ€è¦æ›²ç·šãƒ—ãƒ­ãƒƒãƒˆ
                if "demand_results" in result:
                    demand_plot_path = self.plotter.create_demand_curve_plot(
                        result["demand_results"]
                    )
                    visualization_files.append(demand_plot_path)

                # ç‰¹å¾´é‡é‡è¦åº¦ãƒ—ãƒ­ãƒƒãƒˆ
                if "feature_importance" in result:
                    importance_plot_path = self.plotter.create_feature_importance_plot(
                        result["feature_importance"], result["product_name"]
                    )
                    visualization_files.append(importance_plot_path)

        except Exception as e:
            self.logger.error(f"å¯è¦–åŒ–ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")

        return visualization_files

    def _generate_reports(
        self, analysis_results: List[Dict[str, Any]], quality_report: Dict[str, Any]
    ) -> List[str]:
        """ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        report_files = []

        try:
            # Markdownãƒ¬ãƒãƒ¼ãƒˆ
            markdown_report = self.report_generator.generate_markdown_report(
                analysis_results, quality_report
            )
            markdown_path = self.report_generator.save_markdown_report(markdown_report)
            report_files.append(markdown_path)

            # CSVãƒ¬ãƒãƒ¼ãƒˆ
            csv_paths = self.report_generator.generate_csv_reports(analysis_results)
            report_files.extend(csv_paths)

        except Exception as e:
            self.logger.error(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")

        return report_files

    def _validate_time_series_quality(self, product_data: pd.DataFrame, product_name: str) -> bool:
        """
        æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®å“è³ªã‚’æ¤œè¨¼

        Args:
            product_data: å•†å“ãƒ‡ãƒ¼ã‚¿
            product_name: å•†å“å

        Returns:
            å“è³ªãŒååˆ†ãªã‚‰Trueã€ä¸ååˆ†ãªã‚‰False
        """
        try:
            # æ—¥ä»˜åˆ—ã®å­˜åœ¨ç¢ºèª
            if "å¹´æœˆæ—¥" not in product_data.columns:
                return False

            # æ—¥ä»˜é †ã«ã‚½ãƒ¼ãƒˆ
            product_data_sorted = product_data.sort_values("å¹´æœˆæ—¥")

            # 1. æ™‚ç³»åˆ—é€£ç¶šæ€§ãƒã‚§ãƒƒã‚¯ï¼šãƒ‡ãƒ¼ã‚¿ã®æœŸé–“ã‚’ãƒã‚§ãƒƒã‚¯
            date_range = (
                product_data_sorted["å¹´æœˆæ—¥"].max() - product_data_sorted["å¹´æœˆæ—¥"].min()
            ).days
            if date_range < 90:  # 3ãƒ¶æœˆæœªæº€ã®ãƒ‡ãƒ¼ã‚¿ã¯é™¤å¤–
                self.logger.warning(f"{product_name}: ãƒ‡ãƒ¼ã‚¿æœŸé–“ãŒçŸ­ã™ãã¾ã™ ({date_range}æ—¥)")
                return False

            # 2. ãƒ‡ãƒ¼ã‚¿å¯†åº¦ãƒã‚§ãƒƒã‚¯ï¼šæœŸé–“ã«å¯¾ã™ã‚‹ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ã®å¯†åº¦
            expected_records = date_range * 0.3  # 3æ—¥ã«1å›ç¨‹åº¦ã®å£²ä¸Šã‚’æœŸå¾…
            if len(product_data) < expected_records:
                self.logger.warning(
                    f"{product_name}: ãƒ‡ãƒ¼ã‚¿å¯†åº¦ãŒä½ã™ãã¾ã™ (æœŸé–“:{date_range}æ—¥, ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°:{len(product_data)})"
                )
                return False

            # 3. å­£ç¯€æ€§ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯ï¼šæœˆæ¬¡å£²ä¸Šã®åˆ†æ•£ã‚’ãƒã‚§ãƒƒã‚¯
            if "month" in product_data.columns or "æœˆ" in product_data.columns:
                month_col = "month" if "month" in product_data.columns else "æœˆ"
                monthly_sales = product_data.groupby(month_col)["æ•°é‡"].sum()

                # æœˆæ¬¡å£²ä¸Šã®å¤‰å‹•ä¿‚æ•°ï¼ˆCVï¼‰ã‚’ãƒã‚§ãƒƒã‚¯
                cv = (
                    monthly_sales.std() / monthly_sales.mean()
                    if monthly_sales.mean() > 0
                    else float("inf")
                )
                if cv > 2.0:  # å¤‰å‹•ä¿‚æ•°ãŒ2.0ã‚’è¶…ãˆã‚‹å ´åˆã¯ä¸å®‰å®šã™ãã‚‹
                    self.logger.warning(
                        f"{product_name}: æœˆæ¬¡å£²ä¸Šã®ä¸å®‰å®šæ€§ãŒé«˜ã™ãã¾ã™ (CV: {cv:.2f})"
                    )
                    return False

            # 4. ã‚¼ãƒ­å£²ä¸ŠæœŸé–“ãƒã‚§ãƒƒã‚¯ï¼šé€£ç¶šã™ã‚‹ã‚¼ãƒ­å£²ä¸Šã®æœŸé–“ã‚’ãƒã‚§ãƒƒã‚¯
            zero_sales_ratio = (product_data["æ•°é‡"] == 0).sum() / len(product_data)
            if zero_sales_ratio > 0.5:  # ã‚¼ãƒ­å£²ä¸ŠãŒ50%ã‚’è¶…ãˆã‚‹å ´åˆ
                self.logger.warning(
                    f"{product_name}: ã‚¼ãƒ­å£²ä¸Šã®æ¯”ç‡ãŒé«˜ã™ãã¾ã™ ({zero_sales_ratio:.1%})"
                )
                return False

            return True

        except Exception as e:
            self.logger.error(f"{product_name}: æ™‚ç³»åˆ—å“è³ªæ¤œè¨¼ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def _log_summary(self, results: Dict[str, Any]):
        """çµæœã‚µãƒãƒªãƒ¼ã‚’ãƒ­ã‚°å‡ºåŠ›"""
        summary = results["summary"]

        self.logger.info("=== åˆ†æçµæœã‚µãƒãƒªãƒ¼ ===")
        self.logger.info(f"åˆ†æå•†å“æ•°: {summary['total_products_analyzed']}")
        self.logger.info(f"æˆåŠŸç‡: {summary['success_rate']*100:.1f}%")
        self.logger.info(f"å¹³å‡RÂ²ã‚¹ã‚³ã‚¢: {summary['average_r2']:.3f}")
        self.logger.info(f"ç”Ÿæˆå¯è¦–åŒ–ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(results['visualization_files'])}")
        self.logger.info(f"ç”Ÿæˆãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(results['report_files'])}")
        self.logger.info("========================")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(description="ç”Ÿé®®é£Ÿå“éœ€è¦äºˆæ¸¬ãƒ»åˆ†æã‚·ã‚¹ãƒ†ãƒ ")
    parser.add_argument("--config", type=str, help="è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹")
    parser.add_argument("--products", type=str, nargs="+", help="å¯¾è±¡å•†å“ãƒªã‚¹ãƒˆ")
    parser.add_argument("--max-products", type=int, default=10, help="æœ€å¤§å‡¦ç†å•†å“æ•°")
    parser.add_argument("--verbose", action="store_true", help="è©³ç´°ãƒ­ã‚°å‡ºåŠ›")

    args = parser.parse_args()

    try:
        # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
        pipeline = DemandForecastingPipeline(args.config)

        if args.verbose:
            pipeline.logger.setLevel("DEBUG")

        results = pipeline.run_full_analysis(
            target_products=args.products, max_products=args.max_products
        )

        print("\nâœ… åˆ†æå®Œäº†!")
        print(f"ğŸ“Š åˆ†æå•†å“æ•°: {results['summary']['total_products_analyzed']}")
        print(f"ğŸ“ˆ æˆåŠŸç‡: {results['summary']['success_rate']*100:.1f}%")
        print(f"ğŸ¯ å¹³å‡RÂ²ã‚¹ã‚³ã‚¢: {results['summary']['average_r2']:.3f}")
        print(f"ğŸ“ ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«: {len(results['report_files'])}ä»¶")
        print(f"ğŸ“Š å¯è¦–åŒ–ãƒ•ã‚¡ã‚¤ãƒ«: {len(results['visualization_files'])}ä»¶")

        print("\nğŸ“„ ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«:")
        for file_path in results["report_files"] + results["visualization_files"]:
            print(f"  - {file_path}")

    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
