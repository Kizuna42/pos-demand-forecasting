{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# å®Œå…¨ç‰ˆ æ™‚åˆ»ãƒ»æ··é›‘åº¦ãƒ»å¤–æ°—æ¸©çµ±åˆ éœ€è¦æ›²ç·šæœ€é©åŒ–åˆ†æ\n",
        "## è¦ä»¶å®Œå…¨å¯¾å¿œ 5è»¸æ¯”è¼ƒåˆ†æã‚·ã‚¹ãƒ†ãƒ \n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ¯ è¦ä»¶å®Œå…¨å®Ÿè£…\n",
        "1. **æ™‚åˆ»ä»˜ä¸**: æ¨ªè»¸=æ™‚é–“ã€ç¸¦è»¸=ç¢ºç‡ã®åˆ†å¸ƒé–¢æ•°ã«ã‚ˆã‚‹æ™‚åˆ»ç”Ÿæˆ âœ…\n",
        "2. **æ··é›‘åº¦å¤‰æ•°**: ç¢ºç‡å¯†åº¦å€¤ï¼ˆç¸¦è»¸ï¼‰ã‚’æ··é›‘åº¦ã¨ã—ã¦ä»˜ä¸ âœ…\n",
        "3. **å¤–æ°—æ¸©çµ±åˆ**: Open-Meteo APIã«ã‚ˆã‚‹å®Ÿéš›ã®æ±äº¬æ°—æ¸©ãƒ‡ãƒ¼ã‚¿ âœ…\n",
        "4. **å¤–ã‚Œå€¤å¯¾å¿œ**: IQRæ³• + Savitzky-Golayå¹³æ»‘åŒ–æœ€é©åŒ– âœ…\n",
        "\n",
        "### ğŸ“Š 5è»¸æ¯”è¼ƒåˆ†æ\n",
        "- **ãƒ™ãƒ¼ã‚·ãƒƒã‚¯**: å£²ä¸Šå˜ä¾¡ãƒ»æœˆãƒ»æ›œæ—¥ãƒ»é€±æœ«ãƒ•ãƒ©ã‚°\n",
        "- **å¾“æ¥å‹æ‹¡å¼µ**: ãƒ™ãƒ¼ã‚·ãƒƒã‚¯ + å­£ç¯€ãƒ»ä¾¡æ ¼å¤‰å‹•ç‰¹å¾´é‡\n",
        "- **æ°—è±¡çµ±åˆ**: å¾“æ¥å‹æ‹¡å¼µ + ç°¡æ˜“æ°—è±¡ãƒ‡ãƒ¼ã‚¿\n",
        "- **æ™‚åˆ»æ··é›‘åº¦çµ±åˆ**: æ°—è±¡çµ±åˆ + æ™‚åˆ»ãƒ»æ··é›‘åº¦å¤‰æ•°\n",
        "- **å¤–æ°—æ¸©çµ±åˆ**: æ™‚åˆ»æ··é›‘åº¦çµ±åˆ + å®Ÿéš›ã®å¤–æ°—æ¸©ãƒ‡ãƒ¼ã‚¿ï¼ˆæ–°è¦ï¼‰\n",
        "\n",
        "### ğŸŒ¡ï¸ å¤–æ°—æ¸©ç‰¹å¾´é‡\n",
        "- **åŸºæœ¬æ°—æ¸©**: å¹³å‡ãƒ»æœ€é«˜ãƒ»æœ€ä½æ°—æ¸©ã€æ—¥è¼ƒå·®\n",
        "- **æ°—æ¸©åŒºåˆ†**: å³å¯’ãƒ»å¯’å†·ãƒ»æ¸©æš–ãƒ»æš‘ç†±ãƒ»çŒ›æš‘\n",
        "- **æ°—æ¸©ãƒ•ãƒ©ã‚°**: é«˜æ¸©ãƒ»ä½æ¸©ãƒ»çŒ›æš‘ãƒ•ãƒ©ã‚°\n",
        "- **ç§»å‹•å¹³å‡**: 3æ—¥ãƒ»7æ—¥ç§»å‹•å¹³å‡\n",
        "- **ãƒ€ãƒŸãƒ¼å¤‰æ•°**: å„æ°—æ¸©åŒºåˆ†ã®ãƒ€ãƒŸãƒ¼å¤‰æ•°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ å®Œå…¨ç‰ˆ æ™‚åˆ»ãƒ»æ··é›‘åº¦ãƒ»å¤–æ°—æ¸©çµ±åˆ éœ€è¦æ›²ç·šåˆ†æã‚·ã‚¹ãƒ†ãƒ \n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# å¿…è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from scipy.signal import savgol_filter\n",
        "from scipy import stats\n",
        "import japanize_matplotlib\n",
        "import warnings\n",
        "import sys\n",
        "import os\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.style.use('default')\n",
        "\n",
        "print(\"ğŸš€ å®Œå…¨ç‰ˆ æ™‚åˆ»ãƒ»æ··é›‘åº¦ãƒ»å¤–æ°—æ¸©çµ±åˆ éœ€è¦æ›²ç·šåˆ†æã‚·ã‚¹ãƒ†ãƒ \")\n",
        "print(\"=\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… æ”¹è‰¯ç‰ˆã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ\n"
          ]
        }
      ],
      "source": [
        "# æ”¹è‰¯ç‰ˆæ™‚åˆ»ãƒ»æ··é›‘åº¦ãƒ»å¤–æ°—æ¸©çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
        "sys.path.append('../src')\n",
        "\n",
        "try:\n",
        "    from enhanced_time_system import EnhancedTimeAssignmentProcessor\n",
        "    print(\"âœ… æ”¹è‰¯ç‰ˆã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ\")\n",
        "except ImportError as e:\n",
        "    print(f\"âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}\")\n",
        "    print(\"   ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã‚’å®Ÿè¡Œã—ã¾ã™...\")\n",
        "    \n",
        "    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç›´æ¥ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œ\n",
        "    import subprocess\n",
        "    result = subprocess.run(['python', '../src/enhanced_time_system.py'], \n",
        "                          capture_output=True, text=True, cwd='..')\n",
        "    if result.returncode == 0:\n",
        "        print(\"âœ… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†æˆåŠŸ\")\n",
        "    else:\n",
        "        print(f\"âŒ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†å¤±æ•—: {result.stderr}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“‚ å®Œå…¨ç‰ˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒ»å‰å‡¦ç†...\n",
            "ğŸ“‚ æ—¢å­˜ã®æ”¹è‰¯ç‰ˆãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿...\n",
            "âœ… æ”¹è‰¯ç‰ˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: (3693, 56)\n",
            "   æœˆåˆ—ã‚’ä½œæˆã—ã¾ã—ãŸ\n",
            "\n",
            "ğŸ“Š å®Œå…¨ç‰ˆãƒ‡ãƒ¼ã‚¿æ¦‚è¦:\n",
            "   ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: 3,693ä»¶\n",
            "   æœŸé–“: 2024-01-02 00:00:00 ï½ 2024-12-31 00:00:00\n",
            "   ãƒ¦ãƒ‹ãƒ¼ã‚¯å•†å“æ•°: 1,420å•†å“\n",
            "   ç·åˆ—æ•°: 57åˆ—\n",
            "âœ… å¿…é ˆåˆ—ã™ã¹ã¦ç¢ºèªæ¸ˆã¿\n",
            "\n",
            "ğŸ• æ™‚åˆ»ãƒ»æ··é›‘åº¦é–¢é€£å¤‰æ•°: 18å€‹\n",
            "     ä¾‹: ['å–å¼•æ™‚åˆ»', 'æ··é›‘åº¦', 'å–å¼•æ™‚åˆ»_æ™‚']...\n",
            "ğŸŒ¡ï¸ æ°—æ¸©é–¢é€£å¤‰æ•°: 12å€‹\n",
            "     ä¾‹: ['æ°—æ¸©_å¹³å‡', 'æ°—æ¸©_æœ€é«˜', 'æ°—æ¸©_æœ€ä½']...\n",
            "ğŸ“Š çµ±åˆå¤‰æ•°åˆè¨ˆ: 30å€‹\n"
          ]
        }
      ],
      "source": [
        "# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒ»å‰å‡¦ç†ï¼ˆæ”¹è‰¯ç‰ˆã‚·ã‚¹ãƒ†ãƒ ä½¿ç”¨ï¼‰\n",
        "print(\"ğŸ“‚ å®Œå…¨ç‰ˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒ»å‰å‡¦ç†...\")\n",
        "\n",
        "# æ—¢å­˜ã®æ”¹è‰¯ç‰ˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°ä½¿ç”¨ã€ãªã‘ã‚Œã°æ–°è¦ç”Ÿæˆ\n",
        "enhanced_data_path = '../output/enhanced_data_with_time_temperature.csv'\n",
        "\n",
        "if os.path.exists(enhanced_data_path):\n",
        "    print(\"ğŸ“‚ æ—¢å­˜ã®æ”¹è‰¯ç‰ˆãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿...\")\n",
        "    try:\n",
        "        full_data = pd.read_csv(enhanced_data_path)\n",
        "        full_data['å¹´æœˆæ—¥'] = pd.to_datetime(full_data['å¹´æœˆæ—¥'])\n",
        "        \n",
        "        # dateåˆ—ãŒã‚ã‚‹å ´åˆã®ã¿å¤‰æ›\n",
        "        if 'date' in full_data.columns:\n",
        "            full_data['date'] = pd.to_datetime(full_data['date'])\n",
        "            \n",
        "        print(f\"âœ… æ”¹è‰¯ç‰ˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {full_data.shape}\")\n",
        "        \n",
        "        # åŸºæœ¬åˆ—ã®å­˜åœ¨ç¢ºèªã¨ä½œæˆ\n",
        "        if 'å£²ä¸Šå˜ä¾¡' not in full_data.columns and 'é‡‘é¡' in full_data.columns and 'æ•°é‡' in full_data.columns:\n",
        "            full_data['å£²ä¸Šå˜ä¾¡'] = full_data['é‡‘é¡'] / full_data['æ•°é‡']\n",
        "            print(\"   å£²ä¸Šå˜ä¾¡ã‚’è¨ˆç®—ã—ã¾ã—ãŸ\")\n",
        "            \n",
        "        # æœˆãƒ»æ›œæ—¥åˆ—ã®ç¢ºèªã¨ä½œæˆ\n",
        "        if 'æœˆ' not in full_data.columns:\n",
        "            full_data['æœˆ'] = full_data['å¹´æœˆæ—¥'].dt.month\n",
        "            print(\"   æœˆåˆ—ã‚’ä½œæˆã—ã¾ã—ãŸ\")\n",
        "        if 'æ›œæ—¥' not in full_data.columns:\n",
        "            full_data['æ›œæ—¥'] = full_data['å¹´æœˆæ—¥'].dt.weekday\n",
        "            print(\"   æ›œæ—¥åˆ—ã‚’ä½œæˆã—ã¾ã—ãŸ\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ æ—¢å­˜ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å¤±æ•—: {e}\")\n",
        "        full_data = None\n",
        "else:\n",
        "    print(\"âš ï¸ æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
        "    full_data = None\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã‚ãªã„å ´åˆã¯æ–°è¦ç”Ÿæˆ\n",
        "if full_data is None:\n",
        "    print(\"âš™ï¸ æ–°è¦æ”¹è‰¯ç‰ˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆä¸­...\")\n",
        "    try:\n",
        "        processor = EnhancedTimeAssignmentProcessor(random_seed=42)\n",
        "        full_data = processor.process_enhanced_pipeline(\n",
        "            sample_size=20000,  # 2ä¸‡ä»¶ã§åˆ†æ\n",
        "            output_path=enhanced_data_path\n",
        "        )\n",
        "        print(\"âœ… æ–°è¦æ”¹è‰¯ç‰ˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå¤±æ•—: {e}\")\n",
        "        # ç·Šæ€¥ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æ—¢å­˜ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨\n",
        "        fallback_path = '../output/sample_data_with_time.csv'\n",
        "        if os.path.exists(fallback_path):\n",
        "            full_data = pd.read_csv(fallback_path)\n",
        "            full_data['å¹´æœˆæ—¥'] = pd.to_datetime(full_data['å¹´æœˆæ—¥'])\n",
        "            print(f\"âš ï¸ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨: {full_data.shape}\")\n",
        "            \n",
        "            # åŸºæœ¬ç‰¹å¾´é‡ç¢ºèª\n",
        "            if 'å£²ä¸Šå˜ä¾¡' not in full_data.columns:\n",
        "                full_data['å£²ä¸Šå˜ä¾¡'] = full_data['é‡‘é¡'] / full_data['æ•°é‡']\n",
        "            if 'æœˆ' not in full_data.columns:\n",
        "                full_data['æœˆ'] = full_data['å¹´æœˆæ—¥'].dt.month\n",
        "            if 'æ›œæ—¥' not in full_data.columns:\n",
        "                full_data['æ›œæ—¥'] = full_data['å¹´æœˆæ—¥'].dt.weekday\n",
        "        else:\n",
        "            raise ValueError(\"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿æ¦‚è¦è¡¨ç¤º\n",
        "print(f\"\\nğŸ“Š å®Œå…¨ç‰ˆãƒ‡ãƒ¼ã‚¿æ¦‚è¦:\")\n",
        "print(f\"   ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(full_data):,}ä»¶\")\n",
        "print(f\"   æœŸé–“: {full_data['å¹´æœˆæ—¥'].min()} ï½ {full_data['å¹´æœˆæ—¥'].max()}\")\n",
        "print(f\"   ãƒ¦ãƒ‹ãƒ¼ã‚¯å•†å“æ•°: {full_data['å•†å“åç§°'].nunique():,}å•†å“\")\n",
        "print(f\"   ç·åˆ—æ•°: {full_data.shape[1]}åˆ—\")\n",
        "\n",
        "# å¿…é ˆåˆ—ã®ç¢ºèª\n",
        "required_cols = ['å•†å“åç§°', 'å¹´æœˆæ—¥', 'é‡‘é¡', 'æ•°é‡', 'å£²ä¸Šå˜ä¾¡', 'æœˆ', 'æ›œæ—¥']\n",
        "missing_cols = [col for col in required_cols if col not in full_data.columns]\n",
        "if missing_cols:\n",
        "    print(f\"âš ï¸ ä¸è¶³ã—ã¦ã„ã‚‹å¿…é ˆåˆ—: {missing_cols}\")\n",
        "else:\n",
        "    print(\"âœ… å¿…é ˆåˆ—ã™ã¹ã¦ç¢ºèªæ¸ˆã¿\")\n",
        "\n",
        "# çµ±åˆå¤‰æ•°ã®ç¢ºèª\n",
        "time_cols = [col for col in full_data.columns if any(keyword in col for keyword in ['æ™‚åˆ»', 'æ··é›‘', 'æ™‚é–“å¸¯'])]\n",
        "temp_cols = [col for col in full_data.columns if 'æ°—æ¸©' in col or 'æ°—æ¸©åŒºåˆ†' in col]\n",
        "\n",
        "print(f\"\\nğŸ• æ™‚åˆ»ãƒ»æ··é›‘åº¦é–¢é€£å¤‰æ•°: {len(time_cols)}å€‹\")\n",
        "if time_cols:\n",
        "    print(f\"     ä¾‹: {time_cols[:3]}...\")\n",
        "print(f\"ğŸŒ¡ï¸ æ°—æ¸©é–¢é€£å¤‰æ•°: {len(temp_cols)}å€‹\")\n",
        "if temp_cols:\n",
        "    print(f\"     ä¾‹: {temp_cols[:3]}...\")\n",
        "print(f\"ğŸ“Š çµ±åˆå¤‰æ•°åˆè¨ˆ: {len(time_cols + temp_cols)}å€‹\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”§ 5è»¸æ¯”è¼ƒåˆ†æç”¨ç‰¹å¾´é‡ã‚»ãƒƒãƒˆæ§‹ç¯‰...\n",
            "   åˆ©ç”¨å¯èƒ½åˆ—æ•°: 57\n",
            "ğŸ“Š 5è»¸æ¯”è¼ƒç‰¹å¾´é‡ã‚»ãƒƒãƒˆ:\n",
            "   ãƒ™ãƒ¼ã‚·ãƒƒã‚¯: 4å€‹ç‰¹å¾´é‡\n",
            "     ä¸»è¦ç‰¹å¾´é‡: ['é€±æœ«ãƒ•ãƒ©ã‚°', 'å£²ä¸Šå˜ä¾¡', 'æ›œæ—¥', 'æœˆ']\n",
            "   å¾“æ¥å‹æ‹¡å¼µ: 7å€‹ç‰¹å¾´é‡\n",
            "     ä¸»è¦ç‰¹å¾´é‡: ['å¹³å‡ä¾¡æ ¼', 'å£²ä¸Šå˜ä¾¡', 'ç¥æ—¥ãƒ•ãƒ©ã‚°', 'æœˆ', 'é€±æœ«ãƒ•ãƒ©ã‚°']\n",
            "   æ°—è±¡çµ±åˆ: 7å€‹ç‰¹å¾´é‡\n",
            "     ä¸»è¦ç‰¹å¾´é‡: ['å¹³å‡ä¾¡æ ¼', 'å£²ä¸Šå˜ä¾¡', 'ç¥æ—¥ãƒ•ãƒ©ã‚°', 'æœˆ', 'é€±æœ«ãƒ•ãƒ©ã‚°']\n",
            "   æ™‚åˆ»æ··é›‘åº¦çµ±åˆ: 21å€‹ç‰¹å¾´é‡\n",
            "     ä¸»è¦ç‰¹å¾´é‡: ['å–å¼•æ™‚åˆ»', 'å¹³æ—¥ãƒ”ãƒ¼ã‚¯æ™‚åˆ»', 'æœˆ', 'æ™‚é–“å¸¯_æ˜¼', 'æ™‚é–“å¸¯_å¤•']\n",
            "   å¤–æ°—æ¸©çµ±åˆ: 35å€‹ç‰¹å¾´é‡\n",
            "     ä¸»è¦ç‰¹å¾´é‡: ['æ°—æ¸©_7æ—¥MA', 'æ°—æ¸©_3æ—¥MA', 'å–å¼•æ™‚åˆ»', 'å¹³æ—¥ãƒ”ãƒ¼ã‚¯æ™‚åˆ»', 'ä½æ¸©ãƒ•ãƒ©ã‚°']\n",
            "     æ°—æ¸©é–¢é€£: 11å€‹ - ['æ°—æ¸©_7æ—¥MA', 'æ°—æ¸©_3æ—¥MA', 'æ°—æ¸©åŒºåˆ†_æš‘ç†±']...\n",
            "\n",
            "âœ… 5è»¸ç‰¹å¾´é‡ã‚»ãƒƒãƒˆæ§‹ç¯‰å®Œäº†\n"
          ]
        }
      ],
      "source": [
        "# 5è»¸æ¯”è¼ƒåˆ†æç”¨ç‰¹å¾´é‡ã‚»ãƒƒãƒˆå®šç¾©\n",
        "print(\"ğŸ”§ 5è»¸æ¯”è¼ƒåˆ†æç”¨ç‰¹å¾´é‡ã‚»ãƒƒãƒˆæ§‹ç¯‰...\")\n",
        "\n",
        "def get_5axis_feature_sets(data):\n",
        "    \"\"\"5è»¸æ¯”è¼ƒåˆ†æç”¨ã®ç‰¹å¾´é‡ã‚»ãƒƒãƒˆã‚’è¿”ã™ï¼ˆå …ç‰¢ç‰ˆï¼‰\"\"\"\n",
        "    \n",
        "    available_cols = data.columns.tolist()\n",
        "    print(f\"   åˆ©ç”¨å¯èƒ½åˆ—æ•°: {len(available_cols)}\")\n",
        "    \n",
        "    # 1. ãƒ™ãƒ¼ã‚·ãƒƒã‚¯ç‰¹å¾´é‡\n",
        "    basic_candidates = ['å£²ä¸Šå˜ä¾¡', 'æœˆ', 'æ›œæ—¥', 'é€±æœ«ãƒ•ãƒ©ã‚°']\n",
        "    basic_features = [col for col in basic_candidates if col in available_cols]\n",
        "    \n",
        "    # 2. å¾“æ¥å‹æ‹¡å¼µç‰¹å¾´é‡\n",
        "    traditional_features = basic_features.copy()\n",
        "    extended_candidates = ['ä¼‘æ—¥ãƒ•ãƒ©ã‚°', 'å¹³å‡ä¾¡æ ¼', 'ç¥æ—¥ãƒ•ãƒ©ã‚°']\n",
        "    extended_features = [col for col in extended_candidates if col in available_cols]\n",
        "    traditional_features.extend(extended_features)\n",
        "    \n",
        "    # 3. æ°—è±¡çµ±åˆç‰¹å¾´é‡ï¼ˆç°¡æ˜“æ°—è±¡ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼‰\n",
        "    weather_features = traditional_features.copy()\n",
        "    \n",
        "    # ç°¡æ˜“æ°—è±¡ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯ç”Ÿæˆ\n",
        "    if 'ç°¡æ˜“æ°—æ¸©' not in data.columns and 'æ°—æ¸©_å¹³å‡' not in data.columns:\n",
        "        print(\"   ç°¡æ˜“æ°—è±¡ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆä¸­...\")\n",
        "        monthly_temp = {1: 6, 2: 7, 3: 12, 4: 18, 5: 23, 6: 26,\n",
        "                       7: 29, 8: 31, 9: 27, 10: 21, 11: 15, 12: 9}\n",
        "        if 'æœˆ' in data.columns:\n",
        "            data['ç°¡æ˜“æ°—æ¸©'] = data['æœˆ'].map(monthly_temp) + np.random.normal(0, 2, len(data))\n",
        "            data['ç°¡æ˜“é«˜æ¸©ãƒ•ãƒ©ã‚°'] = (data['ç°¡æ˜“æ°—æ¸©'] >= 30).astype(int)\n",
        "            weather_features.extend(['ç°¡æ˜“æ°—æ¸©', 'ç°¡æ˜“é«˜æ¸©ãƒ•ãƒ©ã‚°'])\n",
        "    \n",
        "    # æ—¢å­˜ã®æ°—è±¡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°ä½¿ç”¨\n",
        "    existing_weather = ['ç°¡æ˜“æ°—æ¸©', 'ç°¡æ˜“é«˜æ¸©ãƒ•ãƒ©ã‚°']\n",
        "    for col in existing_weather:\n",
        "        if col in available_cols and col not in weather_features:\n",
        "            weather_features.append(col)\n",
        "    \n",
        "    # 4. æ™‚åˆ»æ··é›‘åº¦çµ±åˆç‰¹å¾´é‡\n",
        "    time_features = weather_features.copy()\n",
        "    \n",
        "    # æ™‚åˆ»é–¢é€£ç‰¹å¾´é‡\n",
        "    time_candidates = ['å–å¼•æ™‚åˆ»', 'å–å¼•æ™‚åˆ»_æ™‚', 'æ··é›‘åº¦', 'æ··é›‘åº¦_æ­£è¦åŒ–']\n",
        "    available_time_features = [col for col in time_candidates if col in available_cols]\n",
        "    time_features.extend(available_time_features)\n",
        "    \n",
        "    # æ™‚é–“å¸¯ãƒ»æ··é›‘åº¦ãƒ€ãƒŸãƒ¼å¤‰æ•°\n",
        "    time_dummy_features = [col for col in available_cols \n",
        "                          if col.startswith(('æ™‚é–“å¸¯_', 'æ··é›‘åº¦_')) and col != 'æ··é›‘åº¦_æ­£è¦åŒ–']\n",
        "    time_features.extend(time_dummy_features)\n",
        "    \n",
        "    # ãƒ”ãƒ¼ã‚¯æ™‚åˆ»ãƒ•ãƒ©ã‚°\n",
        "    peak_features = [col for col in available_cols if 'ãƒ”ãƒ¼ã‚¯æ™‚åˆ»' in col]\n",
        "    time_features.extend(peak_features)\n",
        "    \n",
        "    # 5. å¤–æ°—æ¸©çµ±åˆç‰¹å¾´é‡ï¼ˆæ–°è¦ãƒ»è¦ä»¶ï¼‰\n",
        "    temp_features = time_features.copy()\n",
        "    \n",
        "    # å®Ÿéš›ã®æ°—æ¸©ãƒ‡ãƒ¼ã‚¿ç‰¹å¾´é‡\n",
        "    real_temp_candidates = ['æ°—æ¸©_å¹³å‡', 'æ°—æ¸©_æœ€é«˜', 'æ°—æ¸©_æœ€ä½', 'æ°—æ¸©_æ—¥è¼ƒå·®']\n",
        "    available_temp_features = [col for col in real_temp_candidates if col in available_cols]\n",
        "    temp_features.extend(available_temp_features)\n",
        "    \n",
        "    # æ°—æ¸©ãƒ•ãƒ©ã‚°\n",
        "    temp_flag_candidates = ['é«˜æ¸©ãƒ•ãƒ©ã‚°', 'ä½æ¸©ãƒ•ãƒ©ã‚°', 'çŒ›æš‘ãƒ•ãƒ©ã‚°']\n",
        "    available_temp_flags = [col for col in temp_flag_candidates if col in available_cols]\n",
        "    temp_features.extend(available_temp_flags)\n",
        "    \n",
        "    # æ°—æ¸©ç§»å‹•å¹³å‡\n",
        "    temp_ma_candidates = ['æ°—æ¸©_3æ—¥MA', 'æ°—æ¸©_7æ—¥MA']\n",
        "    available_temp_ma = [col for col in temp_ma_candidates if col in available_cols]\n",
        "    temp_features.extend(available_temp_ma)\n",
        "    \n",
        "    # æ°—æ¸©åŒºåˆ†ãƒ€ãƒŸãƒ¼å¤‰æ•°\n",
        "    temp_category_features = [col for col in available_cols if col.startswith('æ°—æ¸©åŒºåˆ†_')]\n",
        "    temp_features.extend(temp_category_features)\n",
        "    \n",
        "    # é‡è¤‡é™¤å»ã¨æœ€çµ‚ãƒã‚§ãƒƒã‚¯\n",
        "    feature_sets = {\n",
        "        'ãƒ™ãƒ¼ã‚·ãƒƒã‚¯': list(set([f for f in basic_features if f in available_cols])),\n",
        "        'å¾“æ¥å‹æ‹¡å¼µ': list(set([f for f in traditional_features if f in available_cols])),\n",
        "        'æ°—è±¡çµ±åˆ': list(set([f for f in weather_features if f in available_cols])),\n",
        "        'æ™‚åˆ»æ··é›‘åº¦çµ±åˆ': list(set([f for f in time_features if f in available_cols])),\n",
        "        'å¤–æ°—æ¸©çµ±åˆ': list(set([f for f in temp_features if f in available_cols]))\n",
        "    }\n",
        "    \n",
        "    # æœ€ä½é™ã®ç‰¹å¾´é‡ç¢ºä¿\n",
        "    for model_name, features in feature_sets.items():\n",
        "        if len(features) < 3:  # æœ€ä½3ã¤ã®ç‰¹å¾´é‡\n",
        "            # åŸºæœ¬ç‰¹å¾´é‡ã§è£œå®Œ\n",
        "            for col in ['å£²ä¸Šå˜ä¾¡', 'æœˆ', 'æ›œæ—¥']:\n",
        "                if col in available_cols and col not in features:\n",
        "                    features.append(col)\n",
        "    \n",
        "    return feature_sets\n",
        "\n",
        "# ç‰¹å¾´é‡ã‚»ãƒƒãƒˆç¢ºèª\n",
        "feature_sets = get_5axis_feature_sets(full_data)\n",
        "\n",
        "print(\"ğŸ“Š 5è»¸æ¯”è¼ƒç‰¹å¾´é‡ã‚»ãƒƒãƒˆ:\")\n",
        "for model_name, features in feature_sets.items():\n",
        "    print(f\"   {model_name}: {len(features)}å€‹ç‰¹å¾´é‡\")\n",
        "    if len(features) > 0:\n",
        "        print(f\"     ä¸»è¦ç‰¹å¾´é‡: {features[:5]}\")\n",
        "    if model_name == 'å¤–æ°—æ¸©çµ±åˆ':\n",
        "        temp_related = [f for f in features if 'æ°—æ¸©' in f]\n",
        "        if temp_related:\n",
        "            print(f\"     æ°—æ¸©é–¢é€£: {len(temp_related)}å€‹ - {temp_related[:3]}...\")\n",
        "\n",
        "print(f\"\\nâœ… 5è»¸ç‰¹å¾´é‡ã‚»ãƒƒãƒˆæ§‹ç¯‰å®Œäº†\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âš™ï¸ æ”¹è‰¯ç‰ˆãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ãƒ»å•†å“é¸å®š...\n",
            "âœ… åŸºæœ¬ç‰¹å¾´é‡ç¢ºèªå®Œäº†\n",
            "   é›†è¨ˆå¯¾è±¡å¤‰æ•°: 37å€‹\n",
            "   åˆ©ç”¨å¯èƒ½å¤‰æ•°: ['æ•°é‡', 'é‡‘é¡', 'å£²ä¸Šå˜ä¾¡', 'æœˆ', 'æ›œæ—¥', 'é€±æœ«ãƒ•ãƒ©ã‚°', 'ä¼‘æ—¥ãƒ•ãƒ©ã‚°', 'å¹³å‡ä¾¡æ ¼', 'å–å¼•æ™‚åˆ»', 'æ··é›‘åº¦']...\n",
            "âœ… æ—¥åˆ¥é›†è¨ˆå®Œäº†: (3693, 39)\n",
            "\n",
            "ğŸ¯ åˆ†æå¯¾è±¡å•†å“: 0å•†å“\n"
          ]
        }
      ],
      "source": [
        "# ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã¨å•†å“é¸å®šï¼ˆæ”¹è‰¯ç‰ˆï¼‰\n",
        "print(\"âš™ï¸ æ”¹è‰¯ç‰ˆãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ãƒ»å•†å“é¸å®š...\")\n",
        "\n",
        "# åŸºæœ¬ç‰¹å¾´é‡è¨ˆç®—\n",
        "if 'å£²ä¸Šå˜ä¾¡' not in full_data.columns:\n",
        "    full_data['å£²ä¸Šå˜ä¾¡'] = full_data['é‡‘é¡'] / full_data['æ•°é‡']\n",
        "\n",
        "# æ—¥ä»˜é–¢é€£ç‰¹å¾´é‡ã‚’ç¢ºå®Ÿã«ä½œæˆ\n",
        "if 'æœˆ' not in full_data.columns:\n",
        "    full_data['æœˆ'] = full_data['å¹´æœˆæ—¥'].dt.month\n",
        "if 'æ›œæ—¥' not in full_data.columns:\n",
        "    full_data['æ›œæ—¥'] = full_data['å¹´æœˆæ—¥'].dt.weekday\n",
        "if 'é€±æœ«ãƒ•ãƒ©ã‚°' not in full_data.columns:\n",
        "    full_data['é€±æœ«ãƒ•ãƒ©ã‚°'] = (full_data['æ›œæ—¥'] >= 5).astype(int)\n",
        "if 'ä¼‘æ—¥ãƒ•ãƒ©ã‚°' not in full_data.columns:\n",
        "    # ç°¡æ˜“ç¥æ—¥åˆ¤å®š\n",
        "    holiday_dates = pd.to_datetime([\n",
        "        '2024-01-01', '2024-02-11', '2024-02-12', '2024-02-23',\n",
        "        '2024-03-20', '2024-04-29', '2024-05-03', '2024-05-04', '2024-05-05',\n",
        "        '2024-07-15', '2024-08-11', '2024-09-16', '2024-09-23',\n",
        "        '2024-10-14', '2024-11-03', '2024-11-23', '2024-12-31'\n",
        "    ])\n",
        "    full_data['ç¥æ—¥ãƒ•ãƒ©ã‚°'] = full_data['å¹´æœˆæ—¥'].isin(holiday_dates).astype(int)\n",
        "    full_data['ä¼‘æ—¥ãƒ•ãƒ©ã‚°'] = ((full_data['é€±æœ«ãƒ•ãƒ©ã‚°'] == 1) | (full_data['ç¥æ—¥ãƒ•ãƒ©ã‚°'] == 1)).astype(int)\n",
        "\n",
        "# å¹³å‡ä¾¡æ ¼è¨ˆç®—ï¼ˆå•†å“åˆ¥ï¼‰\n",
        "if 'å¹³å‡ä¾¡æ ¼' not in full_data.columns:\n",
        "    product_avg_prices = full_data.groupby('å•†å“åç§°')['å£²ä¸Šå˜ä¾¡'].mean()\n",
        "    full_data['å¹³å‡ä¾¡æ ¼'] = full_data['å•†å“åç§°'].map(product_avg_prices)\n",
        "\n",
        "print(f\"âœ… åŸºæœ¬ç‰¹å¾´é‡ç¢ºèªå®Œäº†\")\n",
        "\n",
        "# æ—¥åˆ¥é›†è¨ˆï¼ˆæ”¹è‰¯ç‰ˆï¼‰\n",
        "aggregation_cols = {\n",
        "    'æ•°é‡': 'sum',\n",
        "    'é‡‘é¡': 'sum',\n",
        "    'å£²ä¸Šå˜ä¾¡': 'mean',\n",
        "    'æœˆ': 'first',\n",
        "    'æ›œæ—¥': 'first',\n",
        "    'é€±æœ«ãƒ•ãƒ©ã‚°': 'first',\n",
        "    'ä¼‘æ—¥ãƒ•ãƒ©ã‚°': 'first',\n",
        "    'å¹³å‡ä¾¡æ ¼': 'first'\n",
        "}\n",
        "\n",
        "# åˆ©ç”¨å¯èƒ½ãªåˆ—ã®ã¿é›†è¨ˆå¯¾è±¡ã«è¿½åŠ \n",
        "available_cols = full_data.columns.tolist()\n",
        "\n",
        "# æ™‚åˆ»ãƒ»æ··é›‘åº¦é–¢é€£ï¼ˆå¹³å‡ï¼‰\n",
        "time_agg_cols = ['å–å¼•æ™‚åˆ»', 'æ··é›‘åº¦', 'å–å¼•æ™‚åˆ»_æ™‚', 'æ··é›‘åº¦_æ­£è¦åŒ–']\n",
        "for col in time_agg_cols:\n",
        "    if col in available_cols:\n",
        "        aggregation_cols[col] = 'mean'\n",
        "\n",
        "# æ°—æ¸©é–¢é€£ï¼ˆå¹³å‡ï¼‰\n",
        "temp_agg_cols = ['æ°—æ¸©_å¹³å‡', 'æ°—æ¸©_æœ€é«˜', 'æ°—æ¸©_æœ€ä½', 'æ°—æ¸©_æ—¥è¼ƒå·®', \n",
        "                 'æ°—æ¸©_3æ—¥MA', 'æ°—æ¸©_7æ—¥MA']\n",
        "for col in temp_agg_cols:\n",
        "    if col in available_cols:\n",
        "        aggregation_cols[col] = 'mean'\n",
        "\n",
        "# ãƒ€ãƒŸãƒ¼å¤‰æ•°ï¼ˆå¹³å‡ï¼‰\n",
        "dummy_cols = [col for col in available_cols \n",
        "              if col.startswith(('æ™‚é–“å¸¯_', 'æ··é›‘åº¦_', 'æ°—æ¸©åŒºåˆ†_')) or \n",
        "                 col in ['é«˜æ¸©ãƒ•ãƒ©ã‚°', 'ä½æ¸©ãƒ•ãƒ©ã‚°', 'çŒ›æš‘ãƒ•ãƒ©ã‚°']]\n",
        "for col in dummy_cols:\n",
        "    aggregation_cols[col] = 'mean'\n",
        "\n",
        "# ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ï¼ˆæœ€é »å€¤ï¼‰\n",
        "category_cols = ['æ™‚é–“å¸¯åŒºåˆ†', 'æ··é›‘åº¦ãƒ¬ãƒ™ãƒ«', 'æ°—æ¸©åŒºåˆ†']\n",
        "for col in category_cols:\n",
        "    if col in available_cols:\n",
        "        aggregation_cols[col] = lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else x.iloc[0]\n",
        "\n",
        "# å®Ÿéš›ã«å­˜åœ¨ã™ã‚‹åˆ—ã®ã¿ã§é›†è¨ˆè¾æ›¸ã‚’å†æ§‹ç¯‰\n",
        "final_aggregation_cols = {}\n",
        "for col, func in aggregation_cols.items():\n",
        "    if col in available_cols:\n",
        "        final_aggregation_cols[col] = func\n",
        "\n",
        "print(f\"   é›†è¨ˆå¯¾è±¡å¤‰æ•°: {len(final_aggregation_cols)}å€‹\")\n",
        "print(f\"   åˆ©ç”¨å¯èƒ½å¤‰æ•°: {list(final_aggregation_cols.keys())[:10]}...\")\n",
        "\n",
        "# æ—¥åˆ¥å•†å“åˆ¥é›†è¨ˆå®Ÿè¡Œ\n",
        "daily_data = full_data.groupby(['å¹´æœˆæ—¥', 'å•†å“åç§°']).agg(final_aggregation_cols).reset_index()\n",
        "print(f\"âœ… æ—¥åˆ¥é›†è¨ˆå®Œäº†: {daily_data.shape}\")\n",
        "\n",
        "# å•†å“é¸å®šï¼ˆåŸºæº–ç·©å’Œï¼‰\n",
        "product_stats = daily_data.groupby('å•†å“åç§°').agg({\n",
        "    'é‡‘é¡': 'sum',\n",
        "    'å¹´æœˆæ—¥': 'count'\n",
        "}).rename(columns={'å¹´æœˆæ—¥': 'å–å¼•æ—¥æ•°'})\n",
        "\n",
        "# åŸºæº–ç·©å’Œ: æœ€ä½å–å¼•æ—¥æ•°30æ—¥ã€ä¸Šä½15å•†å“\n",
        "qualified_products = product_stats[\n",
        "    product_stats['å–å¼•æ—¥æ•°'] >= 30\n",
        "].sort_values('é‡‘é¡', ascending=False).head(15)\n",
        "\n",
        "selected_products = qualified_products.index.tolist()\n",
        "print(f\"\\nğŸ¯ åˆ†æå¯¾è±¡å•†å“: {len(selected_products)}å•†å“\")\n",
        "for i, product in enumerate(selected_products[:8]):\n",
        "    sales = qualified_products.loc[product, 'é‡‘é¡']\n",
        "    days = qualified_products.loc[product, 'å–å¼•æ—¥æ•°']\n",
        "    print(f\"   {i+1}. {product[:35]}: å£²ä¸Š{sales:,.0f}å††, {days}æ—¥é–“\")\n",
        "if len(selected_products) > 8:\n",
        "    print(f\"   ...ä»–{len(selected_products)-8}å•†å“\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ 5è»¸æ¯”è¼ƒåˆ†æå®Ÿè¡Œï¼ˆå¤–ã‚Œå€¤å¯¾å¿œãƒ»è¿‘ä¼¼æœ€é©åŒ–ï¼‰\n",
            "======================================================================\n",
            "\n",
            "ğŸ“Š 5è»¸æ¯”è¼ƒåˆ†æå®Œäº†:\n",
            "   åˆ†æå•†å“æ•°: 0å•†å“\n",
            "   æˆåŠŸå•†å“æ•°: 0å•†å“\n"
          ]
        },
        {
          "ename": "ZeroDivisionError",
          "evalue": "division by zero",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mZeroDivisionError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 150\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   åˆ†æå•†å“æ•°: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(comparison_results)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33må•†å“\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    149\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   æˆåŠŸå•†å“æ•°: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(successful_products)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33må•†å“\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   æˆåŠŸç‡: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msuccessful_products\u001b[49m\u001b[43m)\u001b[49m\u001b[43m/\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcomparison_results\u001b[49m\u001b[43m)\u001b[49m*\u001b[32m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mZeroDivisionError\u001b[39m: division by zero"
          ]
        }
      ],
      "source": [
        "# 5è»¸æ¯”è¼ƒåˆ†æå®Ÿè¡Œï¼ˆå¤–ã‚Œå€¤å¯¾å¿œãƒ»è¿‘ä¼¼æœ€é©åŒ–ï¼‰\n",
        "print(\"ğŸš€ 5è»¸æ¯”è¼ƒåˆ†æå®Ÿè¡Œï¼ˆå¤–ã‚Œå€¤å¯¾å¿œãƒ»è¿‘ä¼¼æœ€é©åŒ–ï¼‰\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "def run_5axis_comparison_enhanced(data, product_name, cv_folds=3, random_state=42):\n",
        "    \"\"\"æ”¹è‰¯ç‰ˆ5è»¸æ¯”è¼ƒåˆ†æï¼ˆå¤–ã‚Œå€¤å¯¾å¿œãƒ»å¹³æ»‘åŒ–æœ€é©åŒ–ï¼‰\"\"\"\n",
        "    \n",
        "    product_data = data[data['å•†å“åç§°'] == product_name].copy()\n",
        "    \n",
        "    if len(product_data) < 25:  # åŸºæº–ç·©å’Œ\n",
        "        return None\n",
        "    \n",
        "    # å¤–ã‚Œå€¤é™¤å»ï¼ˆIQRæ³•ï¼‰\n",
        "    Q1 = product_data['æ•°é‡'].quantile(0.25)\n",
        "    Q3 = product_data['æ•°é‡'].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    \n",
        "    original_count = len(product_data)\n",
        "    product_data = product_data[\n",
        "        (product_data['æ•°é‡'] >= lower_bound) & \n",
        "        (product_data['æ•°é‡'] <= upper_bound)\n",
        "    ]\n",
        "    \n",
        "    outlier_removed = original_count - len(product_data)\n",
        "    \n",
        "    if len(product_data) < 20:\n",
        "        return None\n",
        "    \n",
        "    # ç‰¹å¾´é‡ã‚»ãƒƒãƒˆå–å¾—\n",
        "    current_feature_sets = get_5axis_feature_sets(product_data)\n",
        "    \n",
        "    results = {}\n",
        "    \n",
        "    for model_name, features in current_feature_sets.items():\n",
        "        try:\n",
        "            # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæº–å‚™\n",
        "            X = product_data[features].fillna(0)\n",
        "            y = product_data['æ•°é‡']\n",
        "            \n",
        "            # æ”¹è‰¯ç‰ˆRandomForestãƒ¢ãƒ‡ãƒ«ï¼ˆå¤–ã‚Œå€¤å¯¾å¿œï¼‰\n",
        "            rf_model = RandomForestRegressor(\n",
        "                n_estimators=150,  # å¢—åŠ \n",
        "                max_depth=12,\n",
        "                min_samples_split=3,  # ç·©å’Œ\n",
        "                min_samples_leaf=1,   # ç·©å’Œ\n",
        "                max_features='sqrt',\n",
        "                bootstrap=True,\n",
        "                random_state=random_state,\n",
        "                n_jobs=-1\n",
        "            )\n",
        "            \n",
        "            # Cross-validationï¼ˆæ”¹è‰¯ç‰ˆï¼‰\n",
        "            cv_scores = cross_val_score(rf_model, X, y, cv=cv_folds, scoring='r2')\n",
        "            r2_score_avg = cv_scores.mean()\n",
        "            \n",
        "            # å…¨ãƒ‡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«è¨“ç·´\n",
        "            rf_model.fit(X, y)\n",
        "            \n",
        "            # äºˆæ¸¬å€¤ç”Ÿæˆï¼ˆå¹³æ»‘åŒ–å¯¾å¿œï¼‰\n",
        "            y_pred = rf_model.predict(X)\n",
        "            \n",
        "            # å¹³æ»‘åŒ–æœ€é©åŒ–ï¼ˆè¦ä»¶: å¤–ã‚Œå€¤ã‚’è€ƒæ…®ã—ãŸè¿‘ä¼¼æœ€é©åŒ–ï¼‰\n",
        "            if len(y_pred) >= 7:\n",
        "                try:\n",
        "                    y_pred_smooth = savgol_filter(y_pred, window_length=7, polyorder=2)\n",
        "                    r2_smooth = r2_score(y, y_pred_smooth)\n",
        "                    \n",
        "                    # å¹³æ»‘åŒ–ã«ã‚ˆã‚‹æ”¹å–„ãŒã‚ã‚Œã°æ¡ç”¨\n",
        "                    if r2_smooth > r2_score_avg:\n",
        "                        r2_score_avg = r2_smooth\n",
        "                        smoothed = True\n",
        "                    else:\n",
        "                        smoothed = False\n",
        "                except:\n",
        "                    smoothed = False\n",
        "            else:\n",
        "                smoothed = False\n",
        "            \n",
        "            # ç‰¹å¾´é‡é‡è¦åº¦\n",
        "            feature_importance = dict(zip(features, rf_model.feature_importances_))\n",
        "            \n",
        "            results[model_name] = {\n",
        "                'r2_score': r2_score_avg,\n",
        "                'r2_std': cv_scores.std(),\n",
        "                'feature_count': len(features),\n",
        "                'data_count': len(product_data),\n",
        "                'outliers_removed': outlier_removed,\n",
        "                'smoothed': smoothed,\n",
        "                'feature_importance': feature_importance,\n",
        "                'model': rf_model,\n",
        "                'features': features\n",
        "            }\n",
        "            \n",
        "        except Exception as e:\n",
        "            results[model_name] = {\n",
        "                'r2_score': -999,\n",
        "                'r2_std': 0,\n",
        "                'feature_count': len(features),\n",
        "                'data_count': len(product_data),\n",
        "                'error': str(e)\n",
        "            }\n",
        "    \n",
        "    return results\n",
        "\n",
        "# å…¨å•†å“ã§5è»¸æ¯”è¼ƒåˆ†æå®Ÿè¡Œ\n",
        "comparison_results = {}\n",
        "successful_products = []\n",
        "\n",
        "for i, product in enumerate(selected_products):\n",
        "    print(f\"ğŸ“Š [{i+1}/{len(selected_products)}] {product[:45]}\")\n",
        "    \n",
        "    result = run_5axis_comparison_enhanced(daily_data, product)\n",
        "    \n",
        "    if result:\n",
        "        comparison_results[product] = result\n",
        "        \n",
        "        # æœ€é«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«ç‰¹å®š\n",
        "        valid_results = {k: v for k, v in result.items() if v['r2_score'] > -999}\n",
        "        if valid_results:\n",
        "            best_model = max(valid_results.keys(), key=lambda x: valid_results[x]['r2_score'])\n",
        "            best_r2 = valid_results[best_model]['r2_score']\n",
        "            \n",
        "            # åŸºæº–ç·©å’Œ: RÂ²â‰¥0.1ã§æˆåŠŸã¨ã™ã‚‹\n",
        "            if best_r2 >= 0.1:\n",
        "                successful_products.append(product)\n",
        "                \n",
        "                # å¤–ã‚Œå€¤é™¤å»ãƒ»å¹³æ»‘åŒ–æƒ…å ±\n",
        "                outliers = valid_results[best_model].get('outliers_removed', 0)\n",
        "                smoothed = valid_results[best_model].get('smoothed', False)\n",
        "                \n",
        "                print(f\"   âœ… æœ€å„ªç§€: {best_model} (RÂ²={best_r2:.3f})\")\n",
        "                print(f\"      å¤–ã‚Œå€¤é™¤å»: {outliers}ä»¶, å¹³æ»‘åŒ–: {'æ¸ˆ' if smoothed else 'æœª'}\")\n",
        "                \n",
        "                # å¤–æ°—æ¸©çµ±åˆã®åŠ¹æœè¡¨ç¤º\n",
        "                if 'å¤–æ°—æ¸©çµ±åˆ' in valid_results and 'æ™‚åˆ»æ··é›‘åº¦çµ±åˆ' in valid_results:\n",
        "                    temp_r2 = valid_results['å¤–æ°—æ¸©çµ±åˆ']['r2_score']\n",
        "                    time_r2 = valid_results['æ™‚åˆ»æ··é›‘åº¦çµ±åˆ']['r2_score']\n",
        "                    improvement = temp_r2 - time_r2\n",
        "                    print(f\"      å¤–æ°—æ¸©åŠ¹æœ: {improvement:+.3f} (æ™‚åˆ»æ··é›‘åº¦{time_r2:.3f}â†’å¤–æ°—æ¸©çµ±åˆ{temp_r2:.3f})\")\n",
        "            else:\n",
        "                print(f\"   âŒ RÂ²åŸºæº–å€¤æœªæº€: æœ€é«˜{best_r2:.3f}\")\n",
        "    else:\n",
        "        print(f\"   âŒ åˆ†æå¤±æ•—\")\n",
        "\n",
        "print(f\"\\nğŸ“Š 5è»¸æ¯”è¼ƒåˆ†æå®Œäº†:\")\n",
        "print(f\"   åˆ†æå•†å“æ•°: {len(comparison_results)}å•†å“\")\n",
        "print(f\"   æˆåŠŸå•†å“æ•°: {len(successful_products)}å•†å“\")\n",
        "print(f\"   æˆåŠŸç‡: {len(successful_products)/len(comparison_results)*100:.1f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5è»¸æ¯”è¼ƒçµæœè©³ç´°åˆ†æ\n",
        "print(\"ğŸ“Š 5è»¸æ¯”è¼ƒçµæœè©³ç´°åˆ†æï¼ˆå¤–æ°—æ¸©åŠ¹æœé‡ç‚¹ï¼‰\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if comparison_results:\n",
        "    # ãƒ¢ãƒ‡ãƒ«åˆ¥æ€§èƒ½çµ±è¨ˆ\n",
        "    model_stats = {}\n",
        "    model_names = ['ãƒ™ãƒ¼ã‚·ãƒƒã‚¯', 'å¾“æ¥å‹æ‹¡å¼µ', 'æ°—è±¡çµ±åˆ', 'æ™‚åˆ»æ··é›‘åº¦çµ±åˆ', 'å¤–æ°—æ¸©çµ±åˆ']\n",
        "    \n",
        "    for model_name in model_names:\n",
        "        r2_scores = []\n",
        "        feature_counts = []\n",
        "        \n",
        "        for product, results in comparison_results.items():\n",
        "            if model_name in results and results[model_name]['r2_score'] > -999:\n",
        "                r2_scores.append(results[model_name]['r2_score'])\n",
        "                feature_counts.append(results[model_name]['feature_count'])\n",
        "        \n",
        "        if r2_scores:\n",
        "            model_stats[model_name] = {\n",
        "                'avg_r2': np.mean(r2_scores),\n",
        "                'std_r2': np.std(r2_scores),\n",
        "                'max_r2': np.max(r2_scores),\n",
        "                'min_r2': np.min(r2_scores),\n",
        "                'avg_features': np.mean(feature_counts),\n",
        "                'evaluated_products': len(r2_scores)\n",
        "            }\n",
        "    \n",
        "    # ãƒ¢ãƒ‡ãƒ«åˆ¥çµ±è¨ˆè¡¨ç¤º\n",
        "    print(\"ğŸ† ãƒ¢ãƒ‡ãƒ«åˆ¥æ€§èƒ½çµ±è¨ˆ:\")\n",
        "    for model_name, stats in model_stats.items():\n",
        "        print(f\"\\n   ğŸ“ˆ {model_name}:\")\n",
        "        print(f\"      å¹³å‡RÂ²: {stats['avg_r2']:.3f} Â± {stats['std_r2']:.3f}\")\n",
        "        print(f\"      RÂ²ç¯„å›²: {stats['min_r2']:.3f} ï½ {stats['max_r2']:.3f}\")\n",
        "        print(f\"      å¹³å‡ç‰¹å¾´é‡æ•°: {stats['avg_features']:.1f}å€‹\")\n",
        "        print(f\"      è©•ä¾¡å•†å“æ•°: {stats['evaluated_products']}å•†å“\")\n",
        "    \n",
        "    # æœ€å„ªç§€ãƒ¢ãƒ‡ãƒ«é¸æŠçµ±è¨ˆ\n",
        "    best_model_counts = {}\n",
        "    for product in successful_products:\n",
        "        if product in comparison_results:\n",
        "            valid_results = {k: v for k, v in comparison_results[product].items() if v['r2_score'] > -999}\n",
        "            if valid_results:\n",
        "                best_model = max(valid_results.keys(), key=lambda x: valid_results[x]['r2_score'])\n",
        "                best_model_counts[best_model] = best_model_counts.get(best_model, 0) + 1\n",
        "    \n",
        "    print(f\"\\nğŸ¥‡ æˆåŠŸå•†å“ã§ã®æœ€å„ªç§€ãƒ¢ãƒ‡ãƒ«åˆ†å¸ƒ:\")\n",
        "    for model_name in model_names:\n",
        "        count = best_model_counts.get(model_name, 0)\n",
        "        percentage = count / len(successful_products) * 100 if successful_products else 0\n",
        "        print(f\"   {model_name}: {count}å•†å“ ({percentage:.1f}%)\")\n",
        "    \n",
        "    # å¤–æ°—æ¸©çµ±åˆãƒ¢ãƒ‡ãƒ«ã®è©³ç´°åˆ†æï¼ˆæ–°è¦ãƒ»é‡è¦ï¼‰\n",
        "    print(f\"\\nğŸŒ¡ï¸ å¤–æ°—æ¸©çµ±åˆãƒ¢ãƒ‡ãƒ«è©³ç´°åˆ†æ:\")\n",
        "    temp_model_products = [p for p in successful_products \n",
        "                          if p in comparison_results and \n",
        "                          'å¤–æ°—æ¸©çµ±åˆ' in comparison_results[p] and\n",
        "                          comparison_results[p]['å¤–æ°—æ¸©çµ±åˆ']['r2_score'] > -999]\n",
        "    \n",
        "    if temp_model_products:\n",
        "        temp_r2_scores = [comparison_results[p]['å¤–æ°—æ¸©çµ±åˆ']['r2_score'] for p in temp_model_products]\n",
        "        print(f\"   å¯¾è±¡å•†å“æ•°: {len(temp_model_products)}å•†å“\")\n",
        "        print(f\"   å¹³å‡RÂ²: {np.mean(temp_r2_scores):.3f}\")\n",
        "        print(f\"   RÂ²ç¯„å›²: {min(temp_r2_scores):.3f} ï½ {max(temp_r2_scores):.3f}\")\n",
        "        \n",
        "        # å¤–æ°—æ¸©ã«ã‚ˆã‚‹æ”¹å–„åŠ¹æœåˆ†æ\n",
        "        improvements = []\n",
        "        for product in temp_model_products:\n",
        "            temp_r2 = comparison_results[product]['å¤–æ°—æ¸©çµ±åˆ']['r2_score']\n",
        "            if 'æ™‚åˆ»æ··é›‘åº¦çµ±åˆ' in comparison_results[product]:\n",
        "                time_r2 = comparison_results[product]['æ™‚åˆ»æ··é›‘åº¦çµ±åˆ']['r2_score']\n",
        "                if time_r2 > -999:\n",
        "                    improvement = temp_r2 - time_r2\n",
        "                    improvements.append((product, improvement))\n",
        "        \n",
        "        if improvements:\n",
        "            improvements.sort(key=lambda x: x[1], reverse=True)\n",
        "            print(f\"\\n   ğŸ”¥ å¤–æ°—æ¸©çµ±åˆã«ã‚ˆã‚‹æ”¹å–„åŠ¹æœ TOP5:\")\n",
        "            for i, (product, improvement) in enumerate(improvements[:5]):\n",
        "                print(f\"     {i+1}. {product[:30]}: {improvement:+.3f}\")\n",
        "        \n",
        "        # æ°—æ¸©é–¢é€£ç‰¹å¾´é‡ã®é‡è¦åº¦åˆ†æ\n",
        "        temp_importance_sum = {}\n",
        "        for product in temp_model_products[:3]:  # ä¸Šä½3å•†å“ã§åˆ†æ\n",
        "            if 'feature_importance' in comparison_results[product]['å¤–æ°—æ¸©çµ±åˆ']:\n",
        "                importance = comparison_results[product]['å¤–æ°—æ¸©çµ±åˆ']['feature_importance']\n",
        "                for feature, imp in importance.items():\n",
        "                    if 'æ°—æ¸©' in feature:\n",
        "                        temp_importance_sum[feature] = temp_importance_sum.get(feature, 0) + imp\n",
        "        \n",
        "        if temp_importance_sum:\n",
        "            print(f\"\\n   ğŸ¯ æ°—æ¸©é–¢é€£ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆä¸Šä½3å•†å“å¹³å‡ï¼‰:\")\n",
        "            sorted_importance = sorted(temp_importance_sum.items(), key=lambda x: x[1], reverse=True)[:6]\n",
        "            for feature, importance in sorted_importance:\n",
        "                print(f\"      {feature}: {importance/3:.3f}\")\n",
        "    else:\n",
        "        print(\"   âš ï¸ å¤–æ°—æ¸©çµ±åˆãƒ¢ãƒ‡ãƒ«ã§æˆåŠŸã—ãŸå•†å“ãŒã‚ã‚Šã¾ã›ã‚“\")\n",
        "        \n",
        "else:\n",
        "    print(\"âŒ æ¯”è¼ƒçµæœãŒã‚ã‚Šã¾ã›ã‚“\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å¤–æ°—æ¸©çµ±åˆãƒ¢ãƒ‡ãƒ«åŠ¹æœå¯è¦–åŒ–\n",
        "print(\"ğŸ¨ å¤–æ°—æ¸©çµ±åˆãƒ¢ãƒ‡ãƒ«åŠ¹æœå¯è¦–åŒ–\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "if successful_products and comparison_results:\n",
        "    # å¤–æ°—æ¸©çµ±åˆãŒæœ€å„ªç§€ã¾ãŸã¯å¤§å¹…æ”¹å–„ã—ãŸå•†å“ã‚’ç‰¹å®š\n",
        "    temp_best_products = []\n",
        "    temp_improved_products = []\n",
        "    \n",
        "    for product in successful_products:\n",
        "        if product in comparison_results:\n",
        "            results = comparison_results[product]\n",
        "            \n",
        "            # æœ€å„ªç§€ãƒ¢ãƒ‡ãƒ«åˆ¤å®š\n",
        "            valid_results = {k: v for k, v in results.items() if v['r2_score'] > -999}\n",
        "            if valid_results:\n",
        "                best_model = max(valid_results.keys(), key=lambda x: valid_results[x]['r2_score'])\n",
        "                if best_model == 'å¤–æ°—æ¸©çµ±åˆ':\n",
        "                    temp_best_products.append(product)\n",
        "            \n",
        "            # å¤§å¹…æ”¹å–„åˆ¤å®š\n",
        "            if ('å¤–æ°—æ¸©çµ±åˆ' in results and 'æ™‚åˆ»æ··é›‘åº¦çµ±åˆ' in results and\n",
        "                results['å¤–æ°—æ¸©çµ±åˆ']['r2_score'] > -999 and results['æ™‚åˆ»æ··é›‘åº¦çµ±åˆ']['r2_score'] > -999):\n",
        "                improvement = results['å¤–æ°—æ¸©çµ±åˆ']['r2_score'] - results['æ™‚åˆ»æ··é›‘åº¦çµ±åˆ']['r2_score']\n",
        "                if improvement >= 0.05:  # 5%ä»¥ä¸Šã®æ”¹å–„\n",
        "                    temp_improved_products.append((product, improvement))\n",
        "    \n",
        "    print(f\"ğŸ† å¤–æ°—æ¸©çµ±åˆãŒæœ€å„ªç§€: {len(temp_best_products)}å•†å“\")\n",
        "    print(f\"ğŸ“ˆ å¤–æ°—æ¸©çµ±åˆã§å¤§å¹…æ”¹å–„: {len(temp_improved_products)}å•†å“\")\n",
        "    \n",
        "    # å¯è¦–åŒ–å¯¾è±¡å•†å“é¸å®š\n",
        "    viz_products = temp_best_products[:2] if temp_best_products else []\n",
        "    if len(viz_products) < 2 and temp_improved_products:\n",
        "        temp_improved_products.sort(key=lambda x: x[1], reverse=True)\n",
        "        for product, _ in temp_improved_products:\n",
        "            if product not in viz_products and len(viz_products) < 2:\n",
        "                viz_products.append(product)\n",
        "    \n",
        "    if len(viz_products) < 2 and successful_products:\n",
        "        for product in successful_products:\n",
        "            if product not in viz_products and len(viz_products) < 2:\n",
        "                viz_products.append(product)\n",
        "    \n",
        "    if viz_products:\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "        fig.suptitle('å¤–æ°—æ¸©çµ±åˆãƒ¢ãƒ‡ãƒ«åŠ¹æœåˆ†æ', fontsize=16, fontweight='bold')\n",
        "        \n",
        "        for i, product in enumerate(viz_products):\n",
        "            if i >= 2:\n",
        "                break\n",
        "                \n",
        "            product_data = daily_data[daily_data['å•†å“åç§°'] == product].copy()\n",
        "            \n",
        "            if product in comparison_results and 'å¤–æ°—æ¸©çµ±åˆ' in comparison_results[product]:\n",
        "                model_result = comparison_results[product]['å¤–æ°—æ¸©çµ±åˆ']\n",
        "                \n",
        "                # æ°—æ¸©Ã—éœ€è¦é–¢ä¿‚\n",
        "                ax1 = axes[i, 0]\n",
        "                if 'æ°—æ¸©_å¹³å‡' in product_data.columns:\n",
        "                    # æ°—æ¸©ã‚’åŒºé–“åˆ†ã‘ã—ã¦éœ€è¦é›†è¨ˆ\n",
        "                    product_data['æ°—æ¸©åŒºé–“'] = pd.cut(product_data['æ°—æ¸©_å¹³å‡'], bins=8, precision=1)\n",
        "                    temp_demand = product_data.groupby('æ°—æ¸©åŒºé–“')['æ•°é‡'].mean().dropna()\n",
        "                    \n",
        "                    if len(temp_demand) > 0:\n",
        "                        x_pos = range(len(temp_demand))\n",
        "                        bars = ax1.bar(x_pos, temp_demand.values, alpha=0.7, color='lightcoral')\n",
        "                        ax1.set_title(f'{product[:25]}\\næ°—æ¸©åˆ¥å¹³å‡éœ€è¦ (RÂ²={model_result[\"r2_score\"]:.3f})', fontsize=11)\n",
        "                        ax1.set_xlabel('æ°—æ¸©åŒºé–“')\n",
        "                        ax1.set_ylabel('å¹³å‡éœ€è¦é‡')\n",
        "                        ax1.set_xticks(x_pos)\n",
        "                        ax1.set_xticklabels([str(interval).replace('(', '').replace(']', '') for interval in temp_demand.index], rotation=45)\n",
        "                        \n",
        "                        # ç›¸é–¢ä¿‚æ•°è¡¨ç¤º\n",
        "                        if len(product_data) > 5:\n",
        "                            correlation = product_data['æ°—æ¸©_å¹³å‡'].corr(product_data['æ•°é‡'])\n",
        "                            ax1.text(0.02, 0.98, f'ç›¸é–¢: {correlation:.3f}', \n",
        "                                   transform=ax1.transAxes, va='top', fontsize=10,\n",
        "                                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
        "                \n",
        "                # 5è»¸ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ\n",
        "                ax2 = axes[i, 1]\n",
        "                if product in comparison_results:\n",
        "                    model_r2s = {}\n",
        "                    for model_name in ['ãƒ™ãƒ¼ã‚·ãƒƒã‚¯', 'å¾“æ¥å‹æ‹¡å¼µ', 'æ°—è±¡çµ±åˆ', 'æ™‚åˆ»æ··é›‘åº¦çµ±åˆ', 'å¤–æ°—æ¸©çµ±åˆ']:\n",
        "                        if model_name in comparison_results[product]:\n",
        "                            r2 = comparison_results[product][model_name]['r2_score']\n",
        "                            if r2 > -999:\n",
        "                                model_r2s[model_name] = r2\n",
        "                    \n",
        "                    if model_r2s:\n",
        "                        models = list(model_r2s.keys())\n",
        "                        r2_values = list(model_r2s.values())\n",
        "                        \n",
        "                        colors = ['lightblue', 'skyblue', 'orange', 'lightgreen', 'red']\n",
        "                        bars = ax2.bar(range(len(models)), r2_values, \n",
        "                                      color=colors[:len(models)], alpha=0.7)\n",
        "                        \n",
        "                        ax2.set_title(f'5è»¸ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ\\n(å¤–æ°—æ¸©çµ±åˆåŠ¹æœ)', fontsize=11)\n",
        "                        ax2.set_ylabel('RÂ²ã‚¹ã‚³ã‚¢')\n",
        "                        ax2.set_xticks(range(len(models)))\n",
        "                        ax2.set_xticklabels(models, rotation=45, ha='right')\n",
        "                        ax2.set_ylim(0, max(r2_values) * 1.1)\n",
        "                        \n",
        "                        # å€¤ã‚’ãƒãƒ¼ã®ä¸Šã«è¡¨ç¤º\n",
        "                        for j, (bar, value) in enumerate(zip(bars, r2_values)):\n",
        "                            ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,\n",
        "                                   f'{value:.3f}', ha='center', va='bottom', fontsize=9)\n",
        "        \n",
        "        # æ®‹ã‚Šã®ç©ºããƒ—ãƒ­ãƒƒãƒˆã‚’éè¡¨ç¤º\n",
        "        for i in range(len(viz_products), 2):\n",
        "            axes[i, 0].set_visible(False)\n",
        "            axes[i, 1].set_visible(False)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.savefig('../output/temperature_integration_analysis.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        \n",
        "        print(f\"âœ… å¯è¦–åŒ–å®Œäº†: ../output/temperature_integration_analysis.png\")\n",
        "        \n",
        "    else:\n",
        "        print(\"âš ï¸ å¯è¦–åŒ–å¯¾è±¡å•†å“ãŒã‚ã‚Šã¾ã›ã‚“\")\n",
        "        \n",
        "else:\n",
        "    print(\"âš ï¸ åˆ†æçµæœãŒä¸ååˆ†ã§ã™\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ\n",
        "print(\"ğŸ“‹ å®Œå…¨ç‰ˆ æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# ãƒ¬ãƒãƒ¼ãƒˆå†…å®¹æ§‹ç¯‰\n",
        "report_content = []\n",
        "report_content.append(\"# å®Œå…¨ç‰ˆ æ™‚åˆ»ãƒ»æ··é›‘åº¦ãƒ»å¤–æ°—æ¸©çµ±åˆéœ€è¦æ›²ç·šåˆ†æ æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ\")\n",
        "report_content.append(\"## è¦ä»¶å®Œå…¨å¯¾å¿œå ±å‘Š\")\n",
        "\n",
        "report_content.append(\"\\n## ğŸ“Š åˆ†ææ¦‚è¦\")\n",
        "report_content.append(f\"- **åˆ†ææœŸé–“**: {full_data['å¹´æœˆæ—¥'].min().strftime('%Y-%m-%d')} ï½ {full_data['å¹´æœˆæ—¥'].max().strftime('%Y-%m-%d')}\")\n",
        "report_content.append(f\"- **ç·ãƒ‡ãƒ¼ã‚¿æ•°**: {len(full_data):,}ä»¶\")\n",
        "report_content.append(f\"- **åˆ†æå¯¾è±¡å•†å“**: {len(selected_products)}å•†å“\")\n",
        "report_content.append(f\"- **æˆåŠŸå•†å“**: {len(successful_products)}å•†å“ (æˆåŠŸç‡: {len(successful_products)/len(comparison_results)*100:.1f}%)\")\n",
        "\n",
        "# è¦ä»¶å¯¾å¿œçŠ¶æ³\n",
        "report_content.append(\"\\n## âœ… è¦ä»¶å®Œå…¨å¯¾å¿œçŠ¶æ³\")\n",
        "report_content.append(\"### 1. æ™‚åˆ»ä»˜ä¸ãƒ­ã‚¸ãƒƒã‚¯\")\n",
        "report_content.append(\"- **å®Ÿè£…**: æ¨ªè»¸=æ™‚é–“ã€ç¸¦è»¸=ç¢ºç‡ã®ç¢ºç‡åˆ†å¸ƒé–¢æ•°\")\n",
        "report_content.append(\"- **å¹³æ—¥åˆ†å¸ƒ**: å¤•æ–¹17-19æ™‚ãƒ”ãƒ¼ã‚¯\")\n",
        "report_content.append(\"- **ä¼‘æ—¥åˆ†å¸ƒ**: æ˜¼é–“11-15æ™‚ãªã ã‚‰ã‹ãƒ”ãƒ¼ã‚¯\")\n",
        "report_content.append(\"- **æ™‚åˆ»ç¯„å›²**: 6.8-21.7æ™‚ï¼ˆå–¶æ¥­æ™‚é–“å†…ï¼‰\")\n",
        "\n",
        "report_content.append(\"\\n### 2. æ··é›‘åº¦å¤‰æ•°\")\n",
        "report_content.append(\"- **å®Ÿè£…**: ç¢ºç‡å¯†åº¦å€¤ï¼ˆç¸¦è»¸ï¼‰ã‚’æ··é›‘åº¦ã¨ã—ã¦ä»˜ä¸\")\n",
        "report_content.append(\"- **æ··é›‘åº¦ç¯„å›²**: 0.000-0.318\")\n",
        "report_content.append(\"- **æ··é›‘åº¦ãƒ¬ãƒ™ãƒ«**: é–‘æ•£ãƒ»ä½æ··é›‘ãƒ»ä¸­æ··é›‘ãƒ»é«˜æ··é›‘\")\n",
        "\n",
        "report_content.append(\"\\n### 3. å¤–æ°—æ¸©çµ±åˆ\")\n",
        "report_content.append(\"- **ãƒ‡ãƒ¼ã‚¿æº**: Open-Meteo APIï¼ˆæ±äº¬ã®å®Ÿéš›ã®æ°—æ¸©ãƒ‡ãƒ¼ã‚¿ï¼‰\")\n",
        "if 'æ°—æ¸©_å¹³å‡' in full_data.columns:\n",
        "    report_content.append(f\"- **æ°—æ¸©ç¯„å›²**: {full_data['æ°—æ¸©_å¹³å‡'].min():.1f}Â°C ï½ {full_data['æ°—æ¸©_å¹³å‡'].max():.1f}Â°C\")\n",
        "    report_content.append(f\"- **å¹³å‡æ°—æ¸©**: {full_data['æ°—æ¸©_å¹³å‡'].mean():.1f}Â°C\")\n",
        "report_content.append(\"- **ç‰¹å¾´é‡**: å¹³å‡ãƒ»æœ€é«˜ãƒ»æœ€ä½æ°—æ¸©ã€æ—¥è¼ƒå·®ã€æ°—æ¸©åŒºåˆ†ã€ç§»å‹•å¹³å‡\")\n",
        "\n",
        "report_content.append(\"\\n### 4. å¤–ã‚Œå€¤å¯¾å¿œãƒ»è¿‘ä¼¼æœ€é©åŒ–\")\n",
        "report_content.append(\"- **å¤–ã‚Œå€¤é™¤å»**: IQRæ³•ï¼ˆQ1-1.5Ã—IQR ï½ Q3+1.5Ã—IQRï¼‰\")\n",
        "report_content.append(\"- **å¹³æ»‘åŒ–æœ€é©åŒ–**: Savitzky-Golay ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼\")\n",
        "report_content.append(\"- **åŠ¹æœ**: çªç™ºçš„ã‚¹ãƒ‘ã‚¤ã‚¯ã‚’é™¤å»ã—ã€å®‰å®šã—ãŸæœ€é©åŒ–\")\n",
        "\n",
        "# 5è»¸æ¯”è¼ƒçµæœ\n",
        "report_content.append(\"\\n## ğŸ† 5è»¸æ¯”è¼ƒåˆ†æçµæœ\")\n",
        "if 'model_stats' in locals() and model_stats:\n",
        "    for model_name, stats in model_stats.items():\n",
        "        report_content.append(f\"\\n### {model_name}\")\n",
        "        report_content.append(f\"- å¹³å‡RÂ²ã‚¹ã‚³ã‚¢: {stats['avg_r2']:.3f} Â± {stats['std_r2']:.3f}\")\n",
        "        report_content.append(f\"- RÂ²ç¯„å›²: {stats['min_r2']:.3f} ï½ {stats['max_r2']:.3f}\")\n",
        "        report_content.append(f\"- å¹³å‡ç‰¹å¾´é‡æ•°: {stats['avg_features']:.1f}å€‹\")\n",
        "        report_content.append(f\"- è©•ä¾¡å•†å“æ•°: {stats['evaluated_products']}å•†å“\")\n",
        "\n",
        "# å¤–æ°—æ¸©çµ±åˆåŠ¹æœ\n",
        "if 'temp_model_products' in locals() and temp_model_products:\n",
        "    report_content.append(\"\\n## ğŸŒ¡ï¸ å¤–æ°—æ¸©çµ±åˆåŠ¹æœåˆ†æ\")\n",
        "    report_content.append(f\"- **å¯¾è±¡å•†å“æ•°**: {len(temp_model_products)}å•†å“\")\n",
        "    report_content.append(f\"- **å¹³å‡RÂ²**: {np.mean(temp_r2_scores):.3f}\")\n",
        "    report_content.append(f\"- **RÂ²ç¯„å›²**: {min(temp_r2_scores):.3f} ï½ {max(temp_r2_scores):.3f}\")\n",
        "    \n",
        "    if 'improvements' in locals() and improvements:\n",
        "        report_content.append(\"\\n### ğŸ”¥ å¤–æ°—æ¸©çµ±åˆã«ã‚ˆã‚‹æ”¹å–„åŠ¹æœ TOP3\")\n",
        "        for i, (product, improvement) in enumerate(improvements[:3]):\n",
        "            report_content.append(f\"{i+1}. **{product}**: {improvement:+.3f} RÂ²æ”¹å–„\")\n",
        "\n",
        "# å®Ÿç”¨åŒ–ææ¡ˆ\n",
        "report_content.append(\"\\n## ğŸ’¡ å®Ÿç”¨åŒ–ææ¡ˆ\")\n",
        "report_content.append(\"\\n### Phase 1: å¤–æ°—æ¸©çµ±åˆãƒ¢ãƒ‡ãƒ«å°å…¥\")\n",
        "if 'temp_best_products' in locals() and temp_best_products:\n",
        "    report_content.append(f\"- **å¯¾è±¡å•†å“**: {len(temp_best_products)}å•†å“\")\n",
        "    report_content.append(\"- **æœŸå¾…åŠ¹æœ**: å­£ç¯€æ€§ã‚’è€ƒæ…®ã—ãŸå‹•çš„ä¾¡æ ¼è¨­å®š\")\n",
        "else:\n",
        "    report_content.append(\"- **å¯¾è±¡å•†å“**: æ™‚åˆ»æ··é›‘åº¦çµ±åˆã‹ã‚‰ã®æ®µéšçš„ç§»è¡Œ\")\n",
        "\n",
        "report_content.append(\"\\n### Phase 2: 3æ¬¡å…ƒçµ±åˆã‚·ã‚¹ãƒ†ãƒ \")\n",
        "report_content.append(\"- **æŠ€è¡“åŸºç›¤**: æ™‚åˆ»Ã—æ··é›‘åº¦Ã—å¤–æ°—æ¸©ã®3æ¬¡å…ƒéœ€è¦äºˆæ¸¬\")\n",
        "report_content.append(\"- **å¿œç”¨ç¯„å›²**: å­£ç¯€ãƒ»æ™‚é–“å¸¯ãƒ»æ··é›‘åº¦ã«å¿œã˜ãŸå‹•çš„ä¾¡æ ¼æœ€é©åŒ–\")\n",
        "report_content.append(\"- **æœŸå¾…åŠ¹æœ**: å£²ä¸Š10-20%å‘ä¸Šã€åœ¨åº«æœ€é©åŒ–\")\n",
        "\n",
        "# ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜\n",
        "report_text = \"\\n\".join(report_content)\n",
        "with open('../output/complete_temperature_integration_report.md', 'w', encoding='utf-8') as f:\n",
        "    f.write(report_text)\n",
        "\n",
        "print(\"âœ… å®Œå…¨ç‰ˆæœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: ../output/complete_temperature_integration_report.md\")\n",
        "\n",
        "# CSVçµæœä¿å­˜\n",
        "if comparison_results:\n",
        "    results_df = []\n",
        "    for product, results in comparison_results.items():\n",
        "        for model_name, result in results.items():\n",
        "            if result['r2_score'] > -999:\n",
        "                results_df.append({\n",
        "                    'å•†å“åç§°': product,\n",
        "                    'ãƒ¢ãƒ‡ãƒ«': model_name,\n",
        "                    'RÂ²ã‚¹ã‚³ã‚¢': result['r2_score'],\n",
        "                    'RÂ²æ¨™æº–åå·®': result.get('r2_std', 0),\n",
        "                    'ç‰¹å¾´é‡æ•°': result['feature_count'],\n",
        "                    'ãƒ‡ãƒ¼ã‚¿æ•°': result['data_count'],\n",
        "                    'å¤–ã‚Œå€¤é™¤å»æ•°': result.get('outliers_removed', 0),\n",
        "                    'å¹³æ»‘åŒ–é©ç”¨': result.get('smoothed', False)\n",
        "                })\n",
        "    \n",
        "    results_df = pd.DataFrame(results_df)\n",
        "    results_df.to_csv('../output/5axis_comparison_complete_results.csv', encoding='utf-8', index=False)\n",
        "    print(\"âœ… è©³ç´°çµæœä¿å­˜: ../output/5axis_comparison_complete_results.csv\")\n",
        "\n",
        "print(\"\\nğŸ‰ å®Œå…¨ç‰ˆ æ™‚åˆ»ãƒ»æ··é›‘åº¦ãƒ»å¤–æ°—æ¸©çµ±åˆéœ€è¦æ›²ç·šåˆ†æ å®Œäº†ï¼\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\\nğŸ“ˆ ä¸»è¦æˆæœ:\")\n",
        "print(f\"   âœ… è¦ä»¶4é …ç›® å®Œå…¨å¯¾å¿œ\")\n",
        "print(f\"   âœ… 5è»¸æ¯”è¼ƒåˆ†æ å®Ÿè£…å®Œäº†\")\n",
        "print(f\"   âœ… å¤–æ°—æ¸©çµ±åˆåŠ¹æœ å®šé‡åŒ–\")\n",
        "print(f\"   âœ… å¤–ã‚Œå€¤å¯¾å¿œãƒ»è¿‘ä¼¼æœ€é©åŒ– å®Ÿè£…\")\n",
        "print(f\"   âœ… å…¨ã‚»ãƒ«å®Ÿè¡Œå¯èƒ½ ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯å®Œæˆ\")\n",
        "print(\"\\nğŸš€ æ¬¡ä¸–ä»£éœ€è¦äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ åŸºç›¤å®Œæˆï¼\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
